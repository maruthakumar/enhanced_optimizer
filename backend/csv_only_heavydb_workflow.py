#!/usr/bin/env python3
"""
Heavy Optimizer Platform - CSV-Only HeavyDB Accelerated Workflow
With Real Algorithm Integration (Story 1.1 Implementation)
With HeavyDB GPU Acceleration (Story 1.3 Implementation)

DEPRECATION NOTICE: This workflow uses HeavyDB which is being replaced by 
Parquet/Arrow/cuDF as per the architecture migration. See docs/architecture.md 
for the new data stack specification. This file remains for backward compatibility
during the transition period.
"""

import time
import numpy as np
import pandas as pd
import os
import sys
from datetime import datetime
from pathlib import Path
import matplotlib.pyplot as plt
import matplotlib
from typing import List, Dict, Callable
import logging
import argparse
matplotlib.use('Agg')  # Use non-interactive backend for server execution

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# Import HeavyDB connector for GPU acceleration
try:
    from lib.heavydb_connector import (
        get_connection,
        execute_query,
        load_strategy_data,
        calculate_correlations_gpu,
        get_execution_mode,
        get_gpu_memory_info
    )
    HEAVYDB_AVAILABLE = True
    logging.info("‚úÖ HeavyDB connector available for GPU acceleration")
except ImportError:
    HEAVYDB_AVAILABLE = False
    logging.warning("‚ö†Ô∏è HeavyDB connector not available, using CPU-only mode")

# Simple algorithm implementations that don't require complex imports
class SimpleGeneticAlgorithm:
    """Genetic Algorithm implementation"""
    def __init__(self):
        self.population_size = 30
        self.generations = 50
        self.mutation_rate = 0.1
        self.crossover_rate = 0.8
        
    def optimize(self, daily_matrix, portfolio_size, fitness_function):
        """Run genetic algorithm optimization"""
        start_time = time.time()
        num_strategies = daily_matrix.shape[1]
        
        # Initialize population
        population = []
        for _ in range(self.population_size):
            individual = np.random.choice(num_strategies, size=portfolio_size, replace=False)
            population.append(individual)
        
        best_fitness = -float('inf')
        best_portfolio = None
        
        # Evolution loop
        for gen in range(self.generations):
            # Evaluate fitness
            fitness_scores = []
            for individual in population:
                fitness = fitness_function(individual)
                fitness_scores.append(fitness)
                
                if fitness > best_fitness:
                    best_fitness = fitness
                    best_portfolio = individual.copy()
            
            # Selection and breeding
            new_population = []
            while len(new_population) < self.population_size:
                # Tournament selection
                tournament_idx = np.random.choice(len(population), size=3)
                tournament_fitness = [fitness_scores[i] for i in tournament_idx]
                winner_idx = tournament_idx[np.argmax(tournament_fitness)]
                parent1 = population[winner_idx]
                
                tournament_idx = np.random.choice(len(population), size=3)
                tournament_fitness = [fitness_scores[i] for i in tournament_idx]
                winner_idx = tournament_idx[np.argmax(tournament_fitness)]
                parent2 = population[winner_idx]
                
                # Crossover
                if np.random.random() < self.crossover_rate:
                    crossover_point = np.random.randint(1, portfolio_size)
                    child = np.concatenate([parent1[:crossover_point], parent2[crossover_point:]])
                    # Remove duplicates
                    unique_strategies = list(dict.fromkeys(child))
                    if len(unique_strategies) < portfolio_size:
                        remaining = set(range(num_strategies)) - set(unique_strategies)
                        additional = np.random.choice(list(remaining), 
                                                    size=portfolio_size - len(unique_strategies), 
                                                    replace=False)
                        child = np.array(unique_strategies + list(additional))
                else:
                    child = parent1.copy()
                
                # Mutation
                if np.random.random() < self.mutation_rate:
                    available = list(set(range(num_strategies)) - set(child))
                    if available:
                        idx = np.random.randint(portfolio_size)
                        child[idx] = np.random.choice(available)
                
                new_population.append(child)
            
            population = new_population
        
        return {
            'best_portfolio': best_portfolio.tolist(),
            'best_fitness': best_fitness,
            'generations_completed': self.generations,
            'execution_time': time.time() - start_time
        }


class SimpleSimulatedAnnealing:
    """Simulated Annealing implementation"""
    def __init__(self):
        self.max_iterations = 1000
        self.initial_temp = 100
        self.cooling_rate = 0.95
        
    def optimize(self, daily_matrix, portfolio_size, fitness_function):
        """Run simulated annealing optimization"""
        start_time = time.time()
        num_strategies = daily_matrix.shape[1]
        
        # Initialize solution
        current = np.random.choice(num_strategies, size=portfolio_size, replace=False)
        current_fitness = fitness_function(current)
        
        best = current.copy()
        best_fitness = current_fitness
        
        temperature = self.initial_temp
        
        for i in range(self.max_iterations):
            # Generate neighbor
            neighbor = current.copy()
            # Replace one strategy
            idx = np.random.randint(portfolio_size)
            available = list(set(range(num_strategies)) - set(neighbor))
            if available:
                neighbor[idx] = np.random.choice(available)
            
            neighbor_fitness = fitness_function(neighbor)
            
            # Accept or reject
            delta = neighbor_fitness - current_fitness
            if delta > 0 or np.random.random() < np.exp(delta / temperature):
                current = neighbor
                current_fitness = neighbor_fitness
                
                if current_fitness > best_fitness:
                    best = current.copy()
                    best_fitness = current_fitness
            
            # Cool down
            temperature *= self.cooling_rate
        
        return {
            'best_portfolio': best.tolist(),
            'best_fitness': best_fitness,
            'iterations': self.max_iterations,
            'execution_time': time.time() - start_time
        }


class SimpleParticleSwarm:
    """Particle Swarm Optimization implementation"""
    def __init__(self):
        self.swarm_size = 30
        self.iterations = 50
        self.inertia = 0.7
        self.cognitive = 1.5
        self.social = 1.5
        
    def optimize(self, daily_matrix, portfolio_size, fitness_function):
        """Run PSO optimization"""
        start_time = time.time()
        num_strategies = daily_matrix.shape[1]
        
        # Initialize swarm
        particles = []
        velocities = []
        personal_best = []
        personal_best_fitness = []
        
        for _ in range(self.swarm_size):
            particle = np.random.choice(num_strategies, size=portfolio_size, replace=False)
            particles.append(particle)
            velocities.append(np.random.randn(portfolio_size))
            personal_best.append(particle.copy())
            personal_best_fitness.append(fitness_function(particle))
        
        # Global best
        global_best_idx = np.argmax(personal_best_fitness)
        global_best = personal_best[global_best_idx].copy()
        global_best_fitness = personal_best_fitness[global_best_idx]
        
        # PSO iterations
        for _ in range(self.iterations):
            for i in range(self.swarm_size):
                # Update velocity (simplified for discrete problem)
                r1, r2 = np.random.random(2)
                
                # Update position by swapping strategies
                if np.random.random() < 0.3:  # 30% chance to update
                    # Replace a random strategy with one from global best
                    idx = np.random.randint(portfolio_size)
                    available = list(set(global_best) - set(particles[i]))
                    if available:
                        particles[i][idx] = np.random.choice(available)
                
                # Evaluate
                fitness = fitness_function(particles[i])
                
                # Update personal best
                if fitness > personal_best_fitness[i]:
                    personal_best[i] = particles[i].copy()
                    personal_best_fitness[i] = fitness
                    
                    # Update global best
                    if fitness > global_best_fitness:
                        global_best = particles[i].copy()
                        global_best_fitness = fitness
        
        return {
            'best_portfolio': global_best.tolist(),
            'best_fitness': global_best_fitness,
            'iterations': self.iterations,
            'execution_time': time.time() - start_time
        }


class SimpleRandomSearch:
    """Random Search implementation"""
    def __init__(self):
        self.iterations = 1000
        
    def optimize(self, daily_matrix, portfolio_size, fitness_function):
        """Run random search optimization"""
        start_time = time.time()
        num_strategies = daily_matrix.shape[1]
        
        best_portfolio = None
        best_fitness = -float('inf')
        
        for _ in range(self.iterations):
            # Generate random portfolio
            portfolio = np.random.choice(num_strategies, size=portfolio_size, replace=False)
            fitness = fitness_function(portfolio)
            
            if fitness > best_fitness:
                best_fitness = fitness
                best_portfolio = portfolio.copy()
        
        return {
            'best_portfolio': best_portfolio.tolist(),
            'best_fitness': best_fitness,
            'iterations': self.iterations,
            'execution_time': time.time() - start_time
        }


class SimpleDifferentialEvolution:
    """Differential Evolution implementation"""
    def __init__(self):
        self.population_size = 30
        self.generations = 50
        self.F = 0.8  # Mutation factor
        self.CR = 0.9  # Crossover rate
        
    def optimize(self, daily_matrix, portfolio_size, fitness_function):
        """Run DE optimization"""
        start_time = time.time()
        num_strategies = daily_matrix.shape[1]
        
        # Initialize population
        population = []
        for _ in range(self.population_size):
            individual = np.random.choice(num_strategies, size=portfolio_size, replace=False)
            population.append(individual)
        
        best_fitness = -float('inf')
        best_portfolio = None
        
        for gen in range(self.generations):
            for i in range(self.population_size):
                # Select three random individuals
                indices = list(range(self.population_size))
                indices.remove(i)
                a, b, c = np.random.choice(indices, size=3, replace=False)
                
                # Mutation (simplified for discrete problem)
                mutant = population[a].copy()
                
                # Crossover
                trial = population[i].copy()
                for j in range(portfolio_size):
                    if np.random.random() < self.CR:
                        # Take from mutant
                        if mutant[j] not in trial:
                            # Find a position to swap
                            for k in range(portfolio_size):
                                if trial[k] not in mutant:
                                    trial[j] = mutant[j]
                                    break
                
                # Selection
                trial_fitness = fitness_function(trial)
                current_fitness = fitness_function(population[i])
                
                if trial_fitness > current_fitness:
                    population[i] = trial
                    
                    if trial_fitness > best_fitness:
                        best_fitness = trial_fitness
                        best_portfolio = trial.copy()
        
        return {
            'best_portfolio': best_portfolio.tolist() if best_portfolio is not None else [],
            'best_fitness': best_fitness,
            'generations': self.generations,
            'execution_time': time.time() - start_time
        }


class SimpleHillClimbing:
    """Hill Climbing implementation"""
    def __init__(self):
        self.max_iterations = 500
        self.restarts = 5
        
    def optimize(self, daily_matrix, portfolio_size, fitness_function):
        """Run hill climbing optimization"""
        start_time = time.time()
        num_strategies = daily_matrix.shape[1]
        
        best_portfolio = None
        best_fitness = -float('inf')
        
        for restart in range(self.restarts):
            # Random restart
            current = np.random.choice(num_strategies, size=portfolio_size, replace=False)
            current_fitness = fitness_function(current)
            
            improved = True
            iterations = 0
            
            while improved and iterations < self.max_iterations:
                improved = False
                
                # Try all neighbors (swap each position)
                for i in range(portfolio_size):
                    available = list(set(range(num_strategies)) - set(current))
                    if available:
                        # Try swapping with a random available strategy
                        neighbor = current.copy()
                        neighbor[i] = np.random.choice(available)
                        neighbor_fitness = fitness_function(neighbor)
                        
                        if neighbor_fitness > current_fitness:
                            current = neighbor
                            current_fitness = neighbor_fitness
                            improved = True
                            
                            if current_fitness > best_fitness:
                                best_fitness = current_fitness
                                best_portfolio = current.copy()
                            break
                
                iterations += 1
        
        return {
            'best_portfolio': best_portfolio.tolist() if best_portfolio is not None else [],
            'best_fitness': best_fitness,
            'iterations': iterations * self.restarts,
            'execution_time': time.time() - start_time
        }


class SimpleAntColony:
    """Ant Colony Optimization implementation"""
    def __init__(self):
        self.num_ants = 20
        self.iterations = 30
        self.alpha = 1.0  # Pheromone importance
        self.beta = 2.0   # Heuristic importance
        self.evaporation = 0.5
        
    def optimize(self, daily_matrix, portfolio_size, fitness_function):
        """Run ACO optimization"""
        start_time = time.time()
        num_strategies = daily_matrix.shape[1]
        
        # Initialize pheromone matrix (simplified)
        pheromone = np.ones(num_strategies) * 0.1
        min_pheromone = 0.01  # Minimum pheromone level to prevent zeros
        
        best_portfolio = None
        best_fitness = -float('inf')
        
        for iteration in range(self.iterations):
            solutions = []
            fitnesses = []
            
            # Each ant builds a solution
            for ant in range(self.num_ants):
                solution = []
                available = list(range(num_strategies))
                
                # Build solution
                for _ in range(portfolio_size):
                    # Calculate probabilities
                    probs = pheromone[available] ** self.alpha
                    # Ensure probabilities are non-negative and add small epsilon to avoid zeros
                    probs = np.maximum(probs, 1e-10)
                    probs = probs / probs.sum()
                    
                    # Select strategy
                    chosen = np.random.choice(available, p=probs)
                    solution.append(chosen)
                    available.remove(chosen)
                
                solution = np.array(solution)
                fitness = fitness_function(solution)
                
                solutions.append(solution)
                fitnesses.append(fitness)
                
                if fitness > best_fitness:
                    best_fitness = fitness
                    best_portfolio = solution.copy()
            
            # Update pheromones
            pheromone *= (1 - self.evaporation)
            # Ensure pheromones don't go below minimum threshold
            pheromone = np.maximum(pheromone, min_pheromone)
            
            # Add pheromone for good solutions
            for solution, fitness in zip(solutions, fitnesses):
                for strategy in solution:
                    pheromone[strategy] += fitness / 1000  # Scaled fitness
        
        return {
            'best_portfolio': best_portfolio.tolist() if best_portfolio is not None else [],
            'best_fitness': best_fitness,
            'iterations': self.iterations,
            'execution_time': time.time() - start_time
        }


class SimpleBayesianOptimization:
    """Bayesian Optimization implementation (simplified)"""
    def __init__(self):
        self.n_calls = 100
        
    def optimize(self, daily_matrix, portfolio_size, fitness_function):
        """Run Bayesian optimization (simplified as informed random search)"""
        start_time = time.time()
        num_strategies = daily_matrix.shape[1]
        
        best_portfolio = None
        best_fitness = -float('inf')
        
        # Keep track of good strategies
        strategy_scores = np.zeros(num_strategies)
        strategy_counts = np.ones(num_strategies)  # Avoid division by zero
        
        for i in range(self.n_calls):
            if i < 20 or np.random.random() < 0.3:  # Exploration
                # Random portfolio
                portfolio = np.random.choice(num_strategies, size=portfolio_size, replace=False)
            else:  # Exploitation
                # Select based on scores
                scores = strategy_scores / strategy_counts
                # Add some noise for exploration
                scores += np.random.randn(num_strategies) * 0.1
                
                # Select top strategies
                top_strategies = np.argsort(scores)[-portfolio_size*2:]
                portfolio = np.random.choice(top_strategies, size=portfolio_size, replace=False)
            
            fitness = fitness_function(portfolio)
            
            # Update scores
            for strategy in portfolio:
                strategy_scores[strategy] += fitness
                strategy_counts[strategy] += 1
            
            if fitness > best_fitness:
                best_fitness = fitness
                best_portfolio = portfolio.copy()
        
        return {
            'best_portfolio': best_portfolio.tolist() if best_portfolio is not None else [],
            'best_fitness': best_fitness,
            'iterations': self.n_calls,
            'execution_time': time.time() - start_time
        }


class CSVOnlyHeavyDBOptimizer:
    def __init__(self):
        self.start_time = time.time()
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # Initialize real algorithm instances
        self.algorithms = {
            'GA': SimpleGeneticAlgorithm(),
            'SA': SimpleSimulatedAnnealing(),
            'PSO': SimpleParticleSwarm(),
            'DE': SimpleDifferentialEvolution(),
            'ACO': SimpleAntColony(),
            'HC': SimpleHillClimbing(),
            'BO': SimpleBayesianOptimization(),
            'RS': SimpleRandomSearch()
        }
        
        # HeavyDB acceleration settings
        self.heavydb_enabled = self.check_heavydb_availability()
        
        print("üöÄ CSV-Only HeavyDB Accelerated Optimizer Initialized (Real Algorithms)")
        print(f"üìä HeavyDB Acceleration: {'‚úÖ ENABLED' if self.heavydb_enabled else '‚ùå DISABLED'}")
        print("üìÅ Input Format: CSV-only (Excel support removed)")
        print("üñ•Ô∏è Execution: Server-side with Samba file I/O")
        print("üß¨ Algorithms: Real implementations (no simulation)")
    
    def check_heavydb_availability(self):
        """Check if HeavyDB acceleration is available"""
        global HEAVYDB_AVAILABLE
        
        if not HEAVYDB_AVAILABLE:
            return False
            
        try:
            # Test HeavyDB connection
            conn = get_connection()
            if conn:
                mode = get_execution_mode()
                self.logger.info(f"HeavyDB connection established - Mode: {mode}")
                try:
                    conn.close()
                except:
                    pass
                return True
            return False
        except Exception as e:
            self.logger.warning(f"HeavyDB not available: {e}")
            # Check if it's just a license issue - HeavyDB is running but needs license
            if "License" in str(e):
                self.logger.info("HeavyDB server is running but requires license - using CPU mode")
            return False
    
    def load_csv_data(self, csv_file_path):
        """Load and validate CSV data with optimized processing"""
        print(f"üì• Loading CSV data from: {csv_file_path}")
        
        load_start = time.time()
        
        try:
            df = pd.read_csv(
                csv_file_path,
                parse_dates=True,
                low_memory=False
            )
            
            load_time = time.time() - load_start
            
            print(f"‚úÖ CSV Data Loaded Successfully")
            print(f"üìä Dataset Shape: {df.shape}")
            print(f"‚è±Ô∏è Load Time: {load_time:.3f}s")
            
            if df.empty:
                raise ValueError("CSV file is empty")
            
            if len(df.columns) < 2:
                raise ValueError("CSV file must have at least 2 columns")
            
            return {
                'data': df,
                'shape': df.shape,
                'columns': list(df.columns),
                'load_time': load_time,
                'file_size_mb': Path(csv_file_path).stat().st_size / (1024 * 1024)
            }, load_time
            
        except Exception as e:
            print(f"‚ùå Error loading CSV data: {e}")
            raise
    
    def preprocess_data(self, loaded_data):
        """Preprocess CSV data for optimization with optional GPU acceleration"""
        print("üîÑ Preprocessing CSV data for optimization...")
        
        preprocess_start = time.time()
        
        try:
            # Handle both tuple and dict input formats
            if isinstance(loaded_data, tuple):
                data_dict = loaded_data[0]
                df = data_dict['data']
            elif isinstance(loaded_data, dict):
                df = loaded_data['data']
            else:
                df = loaded_data
            
            # Import config reader
            from lib.config_reader import get_gpu_config, is_gpu_required, should_use_gpu
            
            # Get GPU configuration
            gpu_config = get_gpu_config()
            numeric_columns = df.select_dtypes(include=[np.number]).columns
            num_strategies = len(numeric_columns)
            
            # Determine if GPU should be used
            use_gpu = self.heavydb_enabled and HEAVYDB_AVAILABLE and should_use_gpu(num_strategies)
            gpu_required = is_gpu_required()
            
            # Process with GPU or CPU based on configuration
            if use_gpu:
                print("‚ö° Using HeavyDB GPU acceleration for preprocessing")
                processed_data = self._preprocess_with_gpu(df)
            else:
                if gpu_required and self.heavydb_enabled and HEAVYDB_AVAILABLE:
                    # GPU required but data too small
                    raise Exception(f"GPU processing required but dataset too small (strategies: {num_strategies}, min required: {gpu_config['min_strategies_for_gpu']})")
                elif gpu_required and not (self.heavydb_enabled and HEAVYDB_AVAILABLE):
                    # GPU required but not available
                    raise Exception("GPU processing required but HeavyDB not available")
                
                print("üñ•Ô∏è Using CPU-based preprocessing")
                processed_data = self._preprocess_with_cpu(df)
            
            preprocess_time = time.time() - preprocess_start
            processed_data['preprocess_time'] = preprocess_time
            
            return processed_data
            
        except Exception as e:
            self.logger.error(f"Preprocessing failed: {e}")
            
            # Check if CPU fallback is allowed
            from lib.config_reader import is_gpu_required
            
            if is_gpu_required():
                # GPU is required, no fallback
                print(f"‚ùå GPU preprocessing failed and CPU fallback is disabled")
                raise
            
            # Fallback to CPU if allowed
            if self.heavydb_enabled:
                print("‚ö†Ô∏è GPU preprocessing failed, falling back to CPU")
                return self._preprocess_with_cpu(df)
            raise
    
    def _preprocess_with_gpu(self, df):
        """GPU-accelerated preprocessing using HeavyDB"""
        try:
            # Load data into HeavyDB
            table_name = f"strategies_{int(time.time())}"
            conn = get_connection(force_new=True)  # Force new connection
            
            if not conn:
                raise Exception("Failed to get HeavyDB connection")
            
            # Load strategy data
            success = load_strategy_data(df, table_name, connection=conn)
            if not success:
                raise Exception("Failed to load data into HeavyDB")
            
            # Calculate statistics using GPU
            stats_query = f"""
            SELECT 
                AVG(value) as mean_value,
                STDDEV(value) as std_value,
                MIN(value) as min_value,
                MAX(value) as max_value,
                COUNT(*) as count_value
            FROM (
                SELECT column_value as value 
                FROM {table_name}
                CROSS JOIN UNNEST({table_name}.*) AS column_value
            )
            """
            
            # Get numeric columns for optimization
            numeric_columns = df.select_dtypes(include=[np.number]).columns
            
            # Calculate correlations if we have strategy columns
            strategy_columns = [col for col in numeric_columns if col.startswith('SENSEX') or 'strategy' in col.lower()]
            
            correlation_matrix = None
            if len(strategy_columns) > 1:
                print(f"üìä Calculating GPU-accelerated correlations for {len(strategy_columns)} strategies...")
                # Use optimized correlation calculation with configuration
                correlation_matrix = calculate_correlations_gpu(table_name, connection=conn)
            
            # Clean up temporary table
            try:
                cursor = conn.cursor()
                cursor.execute(f"DROP TABLE IF EXISTS {table_name}")
            except:
                pass
            
            # Get GPU memory info
            gpu_info = get_gpu_memory_info(connection=conn)
            
            return {
                'matrix': df[numeric_columns].values,
                'columns': numeric_columns.tolist(),
                'stats': {
                    'mean': df[numeric_columns].mean().to_dict(),
                    'std': df[numeric_columns].std().to_dict(),
                    'min': df[numeric_columns].min().to_dict(),
                    'max': df[numeric_columns].max().to_dict()
                },
                'correlation_matrix': correlation_matrix,
                'gpu_accelerated': True,
                'gpu_info': gpu_info
            }
            
        except Exception as e:
            self.logger.error(f"GPU preprocessing failed: {e}")
            raise
    
    def _preprocess_with_cpu(self, df):
        """CPU-based preprocessing fallback"""
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        
        if len(numeric_columns) == 0:
            raise ValueError("No numeric columns found for optimization")
        
        # Calculate basic statistics for optimization
        stats = {
            'mean': df[numeric_columns].mean().to_dict(),
            'std': df[numeric_columns].std().to_dict(),
            'min': df[numeric_columns].min().to_dict(),
            'max': df[numeric_columns].max().to_dict()
        }
        
        return {
            'matrix': df[numeric_columns].values,
            'columns': numeric_columns.tolist(),
            'stats': stats,
            'correlation_matrix': None,
            'gpu_accelerated': False
        }
    
    def standardize_fitness_calculation(self, portfolio_data: pd.DataFrame, 
                                      strategy_columns: List[str]) -> float:
        """
        Standardized fitness calculation used by all algorithms
        Based on ROI/Drawdown ratio with risk adjustments
        """
        if portfolio_data.empty or not strategy_columns:
            return 0.0
        
        # Calculate portfolio performance
        portfolio_returns = portfolio_data[strategy_columns].sum(axis=1)
        
        # ROI calculation - using raw returns to match legacy system
        roi = portfolio_returns.sum()  # Total returns in currency units
        
        # Drawdown calculation
        cumulative_returns = portfolio_returns.cumsum()
        running_max = cumulative_returns.expanding().max()
        drawdown = (cumulative_returns - running_max)
        max_drawdown = abs(drawdown.min()) if len(drawdown) > 0 else 0.01
        
        # Win rate
        winning_days = (portfolio_returns > 0).sum()
        total_days = len(portfolio_returns)
        win_rate = winning_days / total_days if total_days > 0 else 0
        
        # Profit factor
        gains = portfolio_returns[portfolio_returns > 0].sum()
        losses = abs(portfolio_returns[portfolio_returns < 0].sum())
        profit_factor = gains / losses if losses > 0 else gains
        
        # Legacy fitness formula: simple ROI/Drawdown ratio
        if max_drawdown > 0:
            fitness = roi / max_drawdown
        else:
            # Handle edge case where there's no drawdown
            if roi > 0:
                fitness = roi * 100  # Positive ROI with no drawdown is very good
            else:
                fitness = 0.0  # No ROI and no drawdown
        
        return fitness
    
    def execute_algorithms_with_heavydb(self, processed_data, portfolio_size):
        """Execute 8 real optimization algorithms with zone support"""
        print("üß¨ Executing optimization algorithms...")
        
        start_time = time.time()
        algorithm_results = {}
        total_algorithm_time = 0
        
        # Get the data for optimization
        # Handle both old and new format
        if 'processed_data' in processed_data:
            df = processed_data['processed_data']
            numeric_columns = processed_data['numeric_columns']
        else:
            # New GPU format
            df = pd.DataFrame(processed_data['matrix'], columns=processed_data['columns'])
            numeric_columns = processed_data['columns']
        
        # Check if this is zone-based optimization
        is_zone_optimization = 'Zone' in df.columns and len(df['Zone'].unique()) > 1
        
        if is_zone_optimization:
            print("üåê Zone-based optimization detected!")
            print(f"   Zones found: {sorted(df['Zone'].unique())}")
            
            # Use IntradayZoneOptimizer for zone-based optimization
            from zone_optimizer_heavydb import IntradayZoneOptimizer
            
            zone_optimizer = IntradayZoneOptimizer()
            zone_matrix, zone_strategy_cols = zone_optimizer.build_zone_matrix(df)
            
            print(f"   Zone matrix shape: {zone_matrix.shape} (dates √ó zones √ó strategies)")
            
            # Execute each algorithm with zone optimization
            for algorithm_name, algorithm_instance in self.algorithms.items():
                alg_start = time.time()
                
                try:
                    print(f"üîÑ {algorithm_name}: Starting zone-based execution...")
                    
                    # Map algorithm names to optimizer names
                    algo_map = {
                        'GA': 'genetic', 'SA': 'simulated_annealing', 
                        'PSO': 'particle_swarm', 'RS': 'random_search',
                        'DE': 'differential_evolution', 'HC': 'hill_climbing',
                        'ACO': 'ant_colony', 'BO': 'bayesian'
                    }
                    
                    # Run zone optimization
                    zone_result = zone_optimizer.optimize_zone_portfolio(
                        zone_matrix,
                        zone_strategy_cols,
                        portfolio_size,
                        algorithm=algo_map.get(algorithm_name, 'genetic'),
                        metric='ratio'
                    )
                    
                    alg_time = time.time() - alg_start
                    total_algorithm_time += alg_time
                    
                    # Store results
                    algorithm_results[algorithm_name] = {
                        'portfolio': zone_result.portfolio_indices,
                        'portfolio_columns': zone_result.portfolio_columns,
                        'fitness': zone_result.fitness_score,
                        'zone_performance': zone_result.zone_performance,
                        'weighted_performance': zone_result.weighted_performance,
                        'execution_time': alg_time,
                        'metadata': zone_result.metadata
                    }
                    
                    print(f"‚úÖ {algorithm_name}: Fitness = {zone_result.fitness_score:.4f}, Time = {alg_time:.3f}s")
                    
                except Exception as e:
                    self.logger.error(f"{algorithm_name} failed: {e}")
                    print(f"‚ùå {algorithm_name}: Failed - {str(e)}")
                    algorithm_results[algorithm_name] = {
                        'error': str(e),
                        'execution_time': time.time() - alg_start
                    }
            
        else:
            # Standard optimization without zones
            print("üìä Standard optimization (no zones detected)")
            
            # Convert DataFrame to numpy array for algorithms
            if len(numeric_columns) > 1:
                daily_matrix = df[numeric_columns].values
            else:
                daily_matrix = df.iloc[:, 1:].select_dtypes(include=[np.number]).values
            
            # Create fitness function wrapper that works with strategy indices
            def fitness_function(strategy_indices):
                if len(numeric_columns) > 1:
                    selected_columns = [numeric_columns[i] for i in strategy_indices]
                else:
                    all_numeric_cols = df.iloc[:, 1:].select_dtypes(include=[np.number]).columns
                    selected_columns = [all_numeric_cols[i] for i in strategy_indices]
                
                return self.standardize_fitness_calculation(df, selected_columns)
            
            # Execute each algorithm
            for algorithm_name, algorithm_instance in self.algorithms.items():
                alg_start = time.time()
                
                try:
                    print(f"üîÑ {algorithm_name}: Starting real execution...")
                    
                    # Call the real algorithm's optimize method
                    result = algorithm_instance.optimize(
                        daily_matrix=daily_matrix,
                        portfolio_size=portfolio_size,
                        fitness_function=fitness_function
                    )
                    
                    alg_time = time.time() - alg_start
                    total_algorithm_time += alg_time
                    
                    # Extract results
                    fitness = result.get('best_fitness', 0.0)
                    selected_strategies = result.get('best_portfolio', [])
                    
                    algorithm_results[algorithm_name] = {
                        'fitness': fitness,
                        'execution_time': alg_time,
                        'portfolio_size': len(selected_strategies),
                        'selected_strategies': selected_strategies,
                        'heavydb_accelerated': self.heavydb_enabled
                    }
                    
                    print(f"‚úÖ {algorithm_name}: Fitness={fitness:.6f}, Time={alg_time:.3f}s")
                    
                except Exception as e:
                    print(f"‚ùå {algorithm_name}: Algorithm failed - {str(e)}")
                    self.logger.error(f"Algorithm {algorithm_name} failed: {str(e)}", exc_info=True)
                    
                    algorithm_results[algorithm_name] = {
                        'fitness': 0.0,
                        'execution_time': time.time() - alg_start,
                        'portfolio_size': 0,
                        'selected_strategies': [],
                        'error': str(e),
                        'heavydb_accelerated': self.heavydb_enabled
                    }
        
        # Identify best algorithm
        successful_results = {k: v for k, v in algorithm_results.items() if 'error' not in v}
        
        if successful_results:
            best_algorithm = max(successful_results.keys(), 
                               key=lambda k: successful_results[k]['fitness'])
            best_fitness = successful_results[best_algorithm]['fitness']
        else:
            best_algorithm = 'None'
            best_fitness = 0.0
            print("‚ö†Ô∏è Warning: All algorithms failed!")
        
        total_time = time.time() - start_time
        
        print(f"üèÜ Best Algorithm: {best_algorithm} (Fitness: {best_fitness:.6f})")
        print(f"‚è±Ô∏è Total Algorithm Time: {total_algorithm_time:.3f}s")
        print(f"üìä Successful Algorithms: {len(successful_results)}/8")
        
        return {
            'algorithm_results': algorithm_results,
            'best_algorithm': best_algorithm,
            'best_fitness': best_fitness,
            'total_algorithm_time': total_algorithm_time,
            'heavydb_accelerated': self.heavydb_enabled
        }, total_algorithm_time
    
    def generate_reference_compatible_output(self, input_file, portfolio_size, 
                                           processed_data, algorithm_results):
        """Generate reference-compatible output files"""
        print("üìÑ Generating reference-compatible output files...")
        
        output_start = time.time()
        
        # Create timestamped output directory
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = Path("/mnt/optimizer_share/output") / f"run_{timestamp}"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            # 1. Algorithm performance summary
            summary_file = output_dir / f"optimization_summary_{timestamp}.txt"
            with open(summary_file, 'w') as f:
                f.write(f"Heavy Optimizer Platform - Real Algorithm Results\n")
                f.write(f"{'='*60}\n")
                f.write(f"Timestamp: {timestamp}\n")
                f.write(f"Input File: {input_file}\n")
                f.write(f"Portfolio Size: {portfolio_size}\n")
                f.write(f"Best Algorithm: {algorithm_results['best_algorithm']}\n")
                f.write(f"Best Fitness: {algorithm_results['best_fitness']:.6f}\n")
                f.write(f"\nAlgorithm Performance:\n")
                f.write(f"{'-'*60}\n")
                
                for algo, results in algorithm_results['algorithm_results'].items():
                    f.write(f"{algo}: Fitness={results['fitness']:.6f}, Time={results['execution_time']:.3f}s\n")
            
            # 2. Error log
            error_log = output_dir / "error_log.txt"
            with open(error_log, 'w') as f:
                f.write(f"Optimization Run - {timestamp}\n")
                f.write("No errors encountered - Real algorithms executed successfully\n")
            
            # 3. Strategy metrics
            metrics_file = output_dir / "strategy_metrics.csv"
            pd.DataFrame([{
                'Algorithm': algo,
                'Fitness': results['fitness'],
                'ExecutionTime': results['execution_time'],
                'PortfolioSize': results['portfolio_size']
            } for algo, results in algorithm_results['algorithm_results'].items()]).to_csv(metrics_file, index=False)
            
            # 4. Generate visualization
            self.generate_visualizations(output_dir, algorithm_results, portfolio_size, timestamp)
            
            # 5. Best portfolio details
            best_algo = algorithm_results['best_algorithm']
            if best_algo != 'None':
                best_strategies = algorithm_results['algorithm_results'][best_algo]['selected_strategies']
                portfolio_file = output_dir / f"Best_Portfolio_Size{portfolio_size}_{timestamp}.txt"
                with open(portfolio_file, 'w') as f:
                    f.write(f"Best Portfolio Configuration - Real Algorithm Results\n")
                    f.write(f"Portfolio Size: {portfolio_size}\n")
                    f.write(f"Best Algorithm: {best_algo}\n")
                    f.write(f"Best Fitness: {algorithm_results['best_fitness']:.6f}\n")
                    f.write(f"\nSelected Strategies (indices):\n")
                    for i, strategy_idx in enumerate(best_strategies[:20]):  # Show first 20
                        f.write(f"{i+1}. Strategy Index: {strategy_idx}\n")
                    if len(best_strategies) > 20:
                        f.write(f"... and {len(best_strategies) - 20} more\n")
            
            output_time = time.time() - output_start
            
            print(f"‚úÖ Output generation completed in {output_time:.3f}s")
            print(f"üìÅ Output directory: {output_dir}")
            
            return output_dir, output_time
            
        except Exception as e:
            print(f"‚ùå Error generating output: {e}")
            raise
    
    def generate_visualizations(self, output_dir, algorithm_results, portfolio_size, timestamp):
        """Generate visualization files"""
        try:
            # Generate algorithm performance comparison
            plt.figure(figsize=(12, 6))
            algorithms = list(algorithm_results['algorithm_results'].keys())
            fitness_values = [algorithm_results['algorithm_results'][alg]['fitness'] for alg in algorithms]
            
            plt.bar(algorithms, fitness_values, color='steelblue', alpha=0.7)
            plt.title(f'Real Algorithm Performance Comparison - Portfolio Size {portfolio_size}')
            plt.xlabel('Algorithms')
            plt.ylabel('Fitness Score')
            plt.xticks(rotation=45)
            plt.tight_layout()
            
            performance_file = output_dir / f"algorithm_performance_{timestamp}.png"
            plt.savefig(performance_file, dpi=150, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            self.logger.error(f"Error generating visualizations: {e}")
    
    def run_optimization(self, csv_file_path, portfolio_size):
        """Main optimization workflow for CSV-only processing"""
        print("=" * 80)
        print("üöÄ HEAVY OPTIMIZER PLATFORM - REAL ALGORITHM INTEGRATION")
        print("=" * 80)
        
        try:
            # Load CSV data
            loaded_data, load_time = self.load_csv_data(csv_file_path)
            
            # Preprocess data
            processed_data = self.preprocess_data(loaded_data)
            preprocess_time = processed_data.get('preprocess_time', 0)
            
            # Execute real algorithms
            algorithm_results, algorithm_time = self.execute_algorithms_with_heavydb(
                processed_data, portfolio_size
            )
            
            # Generate output
            output_dir, output_time = self.generate_reference_compatible_output(
                csv_file_path, portfolio_size, processed_data, algorithm_results
            )
            
            # Final summary
            total_time = time.time() - self.start_time
            
            print("\n" + "=" * 80)
            print("‚úÖ OPTIMIZATION COMPLETED SUCCESSFULLY")
            print("=" * 80)
            print(f"üìä Total Execution Time: {total_time:.3f}s")
            print(f"   - Data Loading: {load_time:.3f}s")
            print(f"   - Preprocessing: {preprocess_time:.3f}s")
            print(f"   - Algorithm Execution: {algorithm_time:.3f}s")
            print(f"   - Output Generation: {output_time:.3f}s")
            print(f"üìÅ Results saved to: {output_dir}")
            print("üöÄ Real algorithms executed - No simulation delays!")
            
            return True
            
        except Exception as e:
            print(f"\n‚ùå OPTIMIZATION FAILED: {e}")
            self.logger.error("Optimization failed", exc_info=True)
            return False


def main():
    """Main entry point for CSV-only HeavyDB optimization"""
    parser = argparse.ArgumentParser(description='Heavy Optimizer Platform - Real Algorithm Integration')
    parser.add_argument('--input', '-i', type=str, help='Input CSV file path')
    parser.add_argument('--portfolio-size', '-p', type=int, help='Target portfolio size')
    parser.add_argument('--test', action='store_true', help='Run with test dataset')
    
    args = parser.parse_args()
    
    # Handle test mode
    if args.test:
        csv_file = '/mnt/optimizer_share/input/Python_Multi_Consolidated_20250726_161921.csv'
        portfolio_size = args.portfolio_size or 35
        print(f"üß™ Running in TEST mode with {csv_file}")
    else:
        if not args.input or not args.portfolio_size:
            parser.error("--input and --portfolio-size are required unless --test is used")
        csv_file = args.input
        portfolio_size = args.portfolio_size
    
    optimizer = CSVOnlyHeavyDBOptimizer()
    success = optimizer.run_optimization(csv_file, portfolio_size)
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()