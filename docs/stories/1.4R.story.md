# Story 1.4R: ULTA Enhancement Retrofit for Parquet/Arrow/cuDF

## Status
To Do

## Story
**As a** Portfolio Optimization System User,
**I want** to retrofit the ULTA implementation to use cuDF operations instead of HeavyDB,
**so that** strategy inversion works efficiently with the new Parquet/Arrow/cuDF architecture

## Acceptance Criteria
1. Create `cuDFULTACalculator` class with GPU-accelerated ROI/drawdown calculations
2. Inversion rate must match HeavyDB implementation: 15-25% of strategies inverted
3. Process 25,544 strategies in <5 seconds (maintain current performance)
4. Generate identical inversion reports (markdown, JSON, Excel formats)
5. Preserve '_inv' suffix naming convention for inverted strategies
6. Zone optimizer must correctly process both original and inverted strategies

## Tasks / Subtasks

### Task 1: Create cuDFULTACalculator Implementation (AC: 1)
- [ ] Subtask 1.1: Design cuDF-based ULTA calculator class
  - [ ] Create `cuDFULTACalculator` class inheriting from `ULTACalculator`
  - [ ] Implement GPU-accelerated ROI/Drawdown calculations
  - [ ] Add cuDF-based strategy inversion logic
  - [ ] Ensure compatibility with both CPU and GPU modes
- [ ] Subtask 1.2: Implement core ULTA operations in cuDF
  - [ ] Convert ROI calculation to cuDF: `roi = strategy_returns.sum()`
  - [ ] Implement drawdown using cuDF: `drawdown = strategy_returns.min()`
  - [ ] Calculate ratios using GPU operations: `ratio = roi / abs(drawdown)`
  - [ ] Implement inversion logic: `-1 * strategy_returns` for qualified strategies
- [ ] Subtask 1.3: Handle large-scale processing
  - [ ] Implement chunked processing for 100k+ strategies
  - [ ] Add GPU memory management for correlation matrices
  - [ ] Support batch processing to avoid memory overflow
  - [ ] Implement progress tracking for long-running operations

### Task 2: Replace SQL Operations with cuDF (AC: 2)
- [ ] Subtask 2.1: Remove HeavyDB SQL query construction
  - [ ] Replace SQL-based filtering with cuDF boolean indexing
  - [ ] Convert SQL aggregations to cuDF groupby operations
  - [ ] Implement joins using cuDF merge operations
  - [ ] Remove all HeavyDB-specific SQL optimizations
- [ ] Subtask 2.2: Implement cuDF-based metrics calculations
  - [ ] Calculate negative days using: `(strategy_returns < 0).sum()`
  - [ ] Compute negative percentage: `negative_days / total_days`
  - [ ] Apply thresholds using cuDF filtering
  - [ ] Implement conditional inversion with GPU operations
- [ ] Subtask 2.3: Optimize GPU operations
  - [ ] Use vectorized operations for all calculations
  - [ ] Minimize data transfers between CPU and GPU
  - [ ] Implement efficient memory allocation strategies
  - [ ] Profile and optimize bottleneck operations

### Task 3: Pipeline Integration (AC: 3)
- [ ] Subtask 3.1: Integrate with Parquet data loading
  - [ ] Load strategy data from Parquet files
  - [ ] Handle dynamic schema with strategy columns
  - [ ] Support partitioned Parquet for date-based processing
  - [ ] Implement metadata caching for performance
- [ ] Subtask 3.2: Arrow to cuDF conversion for ULTA
  - [ ] Implement efficient Arrow → cuDF conversion
  - [ ] Preserve data types during conversion
  - [ ] Handle null values appropriately
  - [ ] Support zero-copy operations where possible
- [ ] Subtask 3.3: Update data flow architecture
  - [ ] Remove intermediate HeavyDB table creation
  - [ ] Implement direct Parquet → ULTA processing
  - [ ] Update correlation calculations to work with inverted strategies
  - [ ] Ensure zone optimizer compatibility with ULTA output

### Task 4: Maintain ULTA Logic Integrity (AC: 4)
- [ ] Subtask 4.1: Preserve configuration parameters
  - [ ] Maintain existing ULTA configuration structure
  - [ ] Support all current thresholds: ROI, negative days, percentage
  - [ ] Ensure backward compatibility with existing configs
  - [ ] Add new GPU-specific configuration options
- [ ] Subtask 4.2: Implement inversion decision algorithm
  - [ ] Port exact logic: `if roi < threshold AND negative_days >= min AND percentage >= min`
  - [ ] Ensure inverted ratio calculation matches original
  - [ ] Maintain strategy naming convention with '_inv' suffix
  - [ ] Preserve inversion statistics tracking
- [ ] Subtask 4.3: Update reporting functionality
  - [ ] Generate markdown inversion reports using cuDF data
  - [ ] Create JSON statistics with GPU-calculated metrics
  - [ ] Prepare Excel-compatible output formats
  - [ ] Include GPU performance metrics in reports

### Task 5: Testing and Performance Validation (AC: 4)
- [ ] Subtask 5.1: Unit testing for cuDF operations
  - [ ] Test ROI/Drawdown calculations accuracy
  - [ ] Validate inversion logic with edge cases
  - [ ] Test configuration parameter handling
  - [ ] Verify GPU/CPU mode switching
- [ ] Subtask 5.2: Integration testing with full pipeline
  - [ ] Test Parquet → cuDF → ULTA → Correlation flow
  - [ ] Validate with 25,544 strategy production dataset
  - [ ] Test zone optimizer integration with inverted strategies
  - [ ] Verify output report generation
- [ ] Subtask 5.3: Performance benchmarking
  - [ ] Compare HeavyDB vs cuDF ULTA performance
  - [ ] Target: <5 seconds for 25,544 strategies (maintain current)
  - [ ] Test scaling to 100k+ strategies
  - [ ] Document memory usage and GPU utilization

## Dev Notes

### Previous Implementation Context
This retrofit updates the ULTA implementation from Story 1.4, which successfully implemented strategy inversion but relied on HeavyDB. Key features to preserve:
- ROI threshold-based inversion logic
- Negative day percentage calculations
- Configurable inversion parameters
- Comprehensive reporting (markdown, JSON, Excel)

### Architecture Migration
**From (HeavyDB):**
```python
class HeavyDBULTACalculator:
    def calculate_in_heavydb(self, conn, table_name):
        query = "SELECT strategy, SUM(returns) as roi FROM..."
        results = conn.execute(query)
```

**To (cuDF):**
```python
class cuDFULTACalculator:
    def calculate_with_cudf(self, data: cudf.DataFrame):
        roi = data.groupby('strategy')['returns'].sum()
        # GPU-accelerated operations
```

### Data Flow Changes
**Old Pipeline:**
```
CSV → Arrow → HeavyDB → ULTA (SQL) → Zone Optimizer
```

**New Pipeline:**
```
CSV → Parquet → Arrow → cuDF → ULTA (GPU) → Zone Optimizer
```

### Configuration Compatibility
Maintain existing configuration structure:
```ini
[ULTA]
enabled = true
roi_threshold = 0.0
min_negative_days = 10
negative_day_percentage = 0.6
```

### Performance Requirements
- ULTA Processing: <5 seconds for 25,544 strategies
- Memory Usage: <500MB additional overhead
- Inversion Rate: 15-25% typical
- Improvement Ratio: 20-50% for inverted strategies

### File Locations
**Files to Update:**
- `/backend/ulta_calculator.py` - Add cuDFULTACalculator class
- Remove dependencies on `/backend/lib/heavydb_connector/`

**Integration Points:**
- `/backend/parquet_cudf_workflow.py` - Main workflow integration
- `/backend/zone_optimizer.py` - Ensure compatibility with ULTA output
- `/backend/lib/correlation/` - Handle inverted strategy correlations

### Technical Constraints
- Preserve exact ULTA decision logic
- Maintain '_inv' naming convention for inverted strategies
- Support all existing report formats
- Ensure zone optimizer compatibility
- Handle correlation calculations with mixed original/inverted strategies

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-08-03 | 1.0 | Initial ULTA retrofit story for Parquet/Arrow/cuDF migration | Claude Code |

## Dev Agent Record

### Agent Model Used
[To be filled by Dev Agent]

### Debug Log References
[To be updated during implementation]

### Completion Notes List
[To be updated during implementation]

### File List
[To be updated during implementation]

## QA Results

### QA Review Summary
[To be completed by QA Agent after implementation]

### Acceptance Criteria Verification
[To be completed by QA Agent]

### Test Results
[To be completed by QA Agent]

### Code Quality Assessment
[To be completed by QA Agent]

### Issues Found
[To be completed by QA Agent]

### Compliance Check
[To be completed by QA Agent]

### Final QA Verdict
[To be completed by QA Agent]